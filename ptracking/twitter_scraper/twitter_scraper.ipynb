{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptracking.topic.lda_tomoto import tomoto_load_model\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from ptracking.predict import Dataset\n",
    "from ptracking.twitter_scraper.twitter_scraper import TwitterFetcher\n",
    "\n",
    "skf = StratifiedKFold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use this to load the topic features already calculated (stored in topic/tomoto_topic.mdl - change it accordingly below) and their associated model\n",
    "data, model = tomoto_load_model('C:/Users/mihut/Desktop/petition-tracking/ptracking/topic/tomoto_topic.mdl')\n",
    "\n",
    "#use this if you want to manually create the model\n",
    "#data, model = tomoto_topics(30, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute any type of features you want (should be in a dataframe with petition_id as index), in this case twitter features\n",
    "tweets = TwitterFetcher().select_tweet_count()\n",
    "#join topic features and twitter features\n",
    "features = data.join(tweets)\n",
    "\n",
    "#collect other information from the table (no. of signatures, created date, class etc) and join it with the features\n",
    "dataset = Dataset().prepare(columns=[\"created_at\"]).join(features)\n",
    "dataset.sort_values(\"created_at\", inplace=True)\n",
    "dataset = dataset.reset_index()\n",
    "\n",
    "#only select columns containing the features we want from the table (in this case columns starting with the fourth column) as the feature vector\n",
    "X = np.array(dataset.iloc[:,4:].values.tolist())\n",
    "#label vector is always class column\n",
    "y = np.array(dataset['class'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:31:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:31:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:31:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:31:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:31:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0.59, 0.58, 0.59, 0.56, 0.5]\n",
      "0.56\n"
     ]
    }
   ],
   "source": [
    "#this piece of code should be the same for all models, currently working with stratified cross validation and using MCC as metric\n",
    "xgb = XGBClassifier()\n",
    "scores = list()\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "  X_train, X_test = X[train_index], X[test_index]\n",
    "  y_train, y_test = y[train_index], y[test_index]\n",
    "  xgb.fit(X_train, y_train)\n",
    "  y_pred = xgb.predict(X_test)\n",
    "  scores.append(round(matthews_corrcoef(y_test,y_pred),2))\n",
    "\n",
    "print(scores)\n",
    "print(round(np.mean(scores),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.52, 0.55, 0.53, 0.49, 0.47]\n",
      "0.51\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_jobs=-1)\n",
    "scores = list()\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "  X_train, X_test = X[train_index], X[test_index]\n",
    "  y_train, y_test = y[train_index], y[test_index]\n",
    "  knn.fit(X_train, y_train)\n",
    "  y_pred = knn.predict(X_test)\n",
    "  scores.append(round(matthews_corrcoef(y_test,y_pred),2))\n",
    "\n",
    "print(scores)\n",
    "print(round(np.mean(scores),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.26, 0.27, 0.28, 0.24, 0.21]\n",
      "0.25\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(class_weight='balanced')\n",
    "scores = list()\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "  X_train, X_test = X[train_index], X[test_index]\n",
    "  y_train, y_test = y[train_index], y[test_index]\n",
    "  svc.fit(X_train, y_train)\n",
    "  y_pred = svc.predict(X_test)\n",
    "  scores.append(round(matthews_corrcoef(y_test,y_pred),2))\n",
    "\n",
    "print(scores)\n",
    "print(round(np.mean(scores),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.47, 0.45, 0.45, 0.42, 0.41]\n",
      "0.44\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "scores = list()\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "  X_train, X_test = X[train_index], X[test_index]\n",
    "  y_train, y_test = y[train_index], y[test_index]\n",
    "  dt.fit(X_train, y_train)\n",
    "  y_pred = dt.predict(X_test)\n",
    "  scores.append(round(matthews_corrcoef(y_test,y_pred),2))\n",
    "\n",
    "print(scores)\n",
    "print(round(np.mean(scores),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.59, 0.59, 0.58, 0.52, 0.49]\n",
      "0.55\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "scores = list()\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "  X_train, X_test = X[train_index], X[test_index]\n",
    "  y_train, y_test = y[train_index], y[test_index]\n",
    "  rf.fit(X_train, y_train)\n",
    "  y_pred = rf.predict(X_test)\n",
    "  scores.append(round(matthews_corrcoef(y_test,y_pred),2))\n",
    "\n",
    "print(scores)\n",
    "print(round(np.mean(scores),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.54, 0.48, 0.56, 0.5, 0.52]\n",
      "0.52\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier()\n",
    "scores = list()\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "  X_train, X_test = X[train_index], X[test_index]\n",
    "  y_train, y_test = y[train_index], y[test_index]\n",
    "  mlp.fit(X_train, y_train)\n",
    "  y_pred = mlp.predict(X_test)\n",
    "  scores.append(round(matthews_corrcoef(y_test,y_pred),2))\n",
    "\n",
    "print(scores)\n",
    "print(round(np.mean(scores),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.34, 0.32, 0.33, 0.3, 0.3]\n",
      "0.32\n"
     ]
    }
   ],
   "source": [
    "nb = ComplementNB()\n",
    "scores = list()\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "  X_train, X_test = X[train_index], X[test_index]\n",
    "  y_train, y_test = y[train_index], y[test_index]\n",
    "  nb.fit(X_train, y_train)\n",
    "  y_pred = nb.predict(X_test)\n",
    "  scores.append(round(matthews_corrcoef(y_test,y_pred),2))\n",
    "\n",
    "print(scores)\n",
    "print(round(np.mean(scores),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = TwitterFetcher.select('petition_id','created_at')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>petition_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2473913</th>\n",
       "      <td>572973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473914</th>\n",
       "      <td>572973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473915</th>\n",
       "      <td>572973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473916</th>\n",
       "      <td>572973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473917</th>\n",
       "      <td>572973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473908</th>\n",
       "      <td>572973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473909</th>\n",
       "      <td>572973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473910</th>\n",
       "      <td>572973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473911</th>\n",
       "      <td>572973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473912</th>\n",
       "      <td>572973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2487436 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          petition_id\n",
       "tweet_id             \n",
       "2473913        572973\n",
       "2473914        572973\n",
       "2473915        572973\n",
       "2473916        572973\n",
       "2473917        572973\n",
       "...               ...\n",
       "2473908        572973\n",
       "2473909        572973\n",
       "2473910        572973\n",
       "2473911        572973\n",
       "2473912        572973\n",
       "\n",
       "[2487436 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset().prepare(columns=[\"signatures\"])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5b3c29a0712409fdb698920a64b480a30a34a97db840d4a16e4c56e61cf421af"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
