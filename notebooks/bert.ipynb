{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptracking.topic.lda import *\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import matthews_corrcoef, accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from ptracking.topic.lda_tomoto import tomoto_load_model\n",
    "skf = StratifiedKFold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = tomoto_load_model('C:/Users/mihut/Desktop/petition-tracking/ptracking/topic/tomoto_topic.mdl')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptracking.predict import Dataset\n",
    "\n",
    "dataset = Dataset().prepare(columns=[\"created_at\"]).join(topics)\n",
    "dataset.sort_values(\"created_at\", inplace=True)\n",
    "\n",
    "dataset = dataset.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(dataset.iloc[:,4:].values.tolist())\n",
    "y = np.array(dataset['class'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:59:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:59:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:59:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:59:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:00:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0.05, 0.03, 0.0, 0.01, 0.03]\n",
      "0.02\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier()\n",
    "scores = list()\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "  X_train, X_test = X[train_index], X[test_index]\n",
    "  y_train, y_test = y[train_index], y[test_index]\n",
    "  xgb.fit(X_train, y_train)\n",
    "  y_pred = xgb.predict(X_test)\n",
    "  scores.append(round(matthews_corrcoef(y_test,y_pred),2))\n",
    "\n",
    "print(scores)\n",
    "print(round(np.mean(scores),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05, 0.02, 0.0, 0.0, 0.01]\n",
      "0.02\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_jobs=-1)\n",
    "scores = list()\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "  X_train, X_test = X[train_index], X[test_index]\n",
    "  y_train, y_test = y[train_index], y[test_index]\n",
    "  knn.fit(X_train, y_train)\n",
    "  y_pred = knn.predict(X_test)\n",
    "  scores.append(round(matthews_corrcoef(y_test,y_pred),2))\n",
    "\n",
    "print(scores)\n",
    "print(round(np.mean(scores),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "svc = SVC()\n",
    "scores = list()\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "  X_train, X_test = X[train_index], X[test_index]\n",
    "  y_train, y_test = y[train_index], y[test_index]\n",
    "  svc.fit(X_train, y_train)\n",
    "  y_pred = svc.predict(X_test)\n",
    "  scores.append(round(matthews_corrcoef(y_test,y_pred),2))\n",
    "\n",
    "print(scores)\n",
    "print(round(np.mean(scores),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02, 0.04, 0.03, 0.0, 0.01]\n",
      "0.02\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(class_weight='balanced')\n",
    "scores = list()\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "  X_train, X_test = X[train_index], X[test_index]\n",
    "  y_train, y_test = y[train_index], y[test_index]\n",
    "  svc.fit(X_train, y_train)\n",
    "  y_pred = svc.predict(X_test)\n",
    "  scores.append(round(matthews_corrcoef(y_test,y_pred),2))\n",
    "\n",
    "print(scores)\n",
    "print(round(np.mean(scores),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06, 0.07, 0.05, 0.03, 0.07]\n",
      "0.06\n"
     ]
    }
   ],
   "source": [
    "nb = ComplementNB()\n",
    "scores = list()\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "  X_train, X_test = X[train_index], X[test_index]\n",
    "  y_train, y_test = y[train_index], y[test_index]\n",
    "  nb.fit(X_train, y_train)\n",
    "  y_pred = nb.predict(X_test)\n",
    "  scores.append(round(matthews_corrcoef(y_test,y_pred),2))\n",
    "\n",
    "print(scores)\n",
    "print(round(np.mean(scores),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01, 0.02, 0.01, 0.03, 0.03]\n",
      "0.02\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "scores = list()\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "  X_train, X_test = X[train_index], X[test_index]\n",
    "  y_train, y_test = y[train_index], y[test_index]\n",
    "  dt.fit(X_train, y_train)\n",
    "  y_pred = dt.predict(X_test)\n",
    "  scores.append(round(matthews_corrcoef(y_test,y_pred),2))\n",
    "\n",
    "print(scores)\n",
    "print(round(np.mean(scores),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01, 0.0, 0.02, 0.03, -0.0]\n",
      "0.01\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "scores = list()\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "  X_train, X_test = X[train_index], X[test_index]\n",
    "  y_train, y_test = y[train_index], y[test_index]\n",
    "  rf.fit(X_train, y_train)\n",
    "  y_pred = rf.predict(X_test)\n",
    "  scores.append(round(matthews_corrcoef(y_test,y_pred),2))\n",
    "\n",
    "print(scores)\n",
    "print(round(np.mean(scores),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mihut\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mihut\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mihut\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mihut\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02, 0.03, 0.04, 0.04, 0.05]\n",
      "0.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mihut\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier()\n",
    "scores = list()\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "  X_train, X_test = X[train_index], X[test_index]\n",
    "  y_train, y_test = y[train_index], y[test_index]\n",
    "  mlp.fit(X_train, y_train)\n",
    "  y_pred = mlp.predict(X_test)\n",
    "  scores.append(round(matthews_corrcoef(y_test,y_pred),2))\n",
    "\n",
    "print(scores)\n",
    "print(round(np.mean(scores),2))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8a98825134ff8ede45dc7c86b38b3b5fbe3144690d83619ea9060570621c6e61"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
